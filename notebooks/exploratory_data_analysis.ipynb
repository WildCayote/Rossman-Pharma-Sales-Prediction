{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add scripts path to the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\KifiyaAIM-Course\\Week - 4\\Rossman-Pharma-Sales-Prediction\\notebooks\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "\n",
    "# Get the parent directory\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "scripts_path = os.path.join(parent_dir, 'scripts')\n",
    "\n",
    "# Insert the path to the parent directory\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "# Insert the path to the Scripts directory\n",
    "sys.path.insert(0, scripts_path)\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scripts.utils import config_logger, log_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize custom logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config the logging file\n",
    "config_logger(log_file='../eda_log.log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paths to the csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path of the store data\n",
    "STORE_PATH  = '../data/store.csv'\n",
    "\n",
    "# path of the pre-compiled train data\n",
    "TRAIN_PATH = '../data/train.csv'\n",
    "\n",
    "# path of the pre-compiled test data\n",
    "TEST_DATA = '../data/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VICTUS 16\\AppData\\Local\\Temp\\ipykernel_2700\\4223236660.py:5: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_pre_df = pd.read_csv(TRAIN_PATH)\n"
     ]
    }
   ],
   "source": [
    "# load the store data\n",
    "store_df = pd.read_csv(STORE_PATH)\n",
    "\n",
    "# load the pre-compiled train data\n",
    "train_pre_df = pd.read_csv(TRAIN_PATH)\n",
    "\n",
    "# load the pre-compiled test data\n",
    "test_pre_df = pd.read_csv(TEST_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 17:08:47,759 - INFO - Finished loading all the provided data\n"
     ]
    }
   ],
   "source": [
    "# log about logging the data\n",
    "log_message(msg='Finished loading all the provided data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A general overview of the data provided**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1115 entries, 0 to 1114\n",
      "Data columns (total 10 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Store                      1115 non-null   int64  \n",
      " 1   StoreType                  1115 non-null   object \n",
      " 2   Assortment                 1115 non-null   object \n",
      " 3   CompetitionDistance        1112 non-null   float64\n",
      " 4   CompetitionOpenSinceMonth  761 non-null    float64\n",
      " 5   CompetitionOpenSinceYear   761 non-null    float64\n",
      " 6   Promo2                     1115 non-null   int64  \n",
      " 7   Promo2SinceWeek            571 non-null    float64\n",
      " 8   Promo2SinceYear            571 non-null    float64\n",
      " 9   PromoInterval              571 non-null    object \n",
      "dtypes: float64(5), int64(2), object(3)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "store_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1017209 entries, 0 to 1017208\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count    Dtype \n",
      "---  ------         --------------    ----- \n",
      " 0   Store          1017209 non-null  int64 \n",
      " 1   DayOfWeek      1017209 non-null  int64 \n",
      " 2   Date           1017209 non-null  object\n",
      " 3   Sales          1017209 non-null  int64 \n",
      " 4   Customers      1017209 non-null  int64 \n",
      " 5   Open           1017209 non-null  int64 \n",
      " 6   Promo          1017209 non-null  int64 \n",
      " 7   StateHoliday   1017209 non-null  object\n",
      " 8   SchoolHoliday  1017209 non-null  int64 \n",
      "dtypes: int64(7), object(2)\n",
      "memory usage: 69.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train_pre_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the basic overview of the two datasets it is clear that:\n",
    "* The data found in the _store.csv_ is a data about unique stores and it contains fields like corresponding stores assortment level, store type and competition distance\n",
    "* The data found in the _train.csv_ is a data about the history of sales for each store. It contains valueable information such as the amount of customers, whether it was open or not, the amount of sales, and whether there was a promo that day or not "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of the data sets have no missing values for any of their columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 17:35:02,899 - INFO - Finished basic understanding of the datasets\n"
     ]
    }
   ],
   "source": [
    "log_message('Finished basic understanding of the datasets')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
